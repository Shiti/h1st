services:
    api:
        build: .
        command: python manage.py runserver 0.0.0.0:8000
        ports:
            - "8000:8000"
    tf_serving:
        ports:
            - "8501:8501"
        volumes:
            - ./model_repo/tensorflow_models/:/models/
        image: tensorflow/serving
        command: --model_config_file=/models/models.config --model_config_file_poll_wait_seconds=6
    pt_serving:
        ports:
            - "8080:8080"
            - "8081:8081"
        volumes:
            - ./model_repo/pytorch_models:/home/model-server/model-store
        image: pytorch/torchserve
