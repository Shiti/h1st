#!/bin/bash

# start TensorFlow server
docker run -d -t --rm -p 8501:8501 --name tf_serving -v "$(pwd)/model_repo/tensorflow_models/:/models/" -v "$(pwd)/monitoring:/monitoring" tensorflow/serving --model_config_file=/models/models.config --model_config_file_poll_wait_seconds=60 --monitoring_config_file=/monitoring/prometheus.config --rest_api_port 8500

# start Pytorch server
docker run -d -t --rm -p 8080:8080 -p 8081:8081 --name pt_serving -v $(pwd)/model_repo/pytorch_models:/home/model-server/model-store pytorch/torchserve:latest

# start Django server
# docker run -d --rm -t -p 8000:8000 --name h1st_api h1st_api
